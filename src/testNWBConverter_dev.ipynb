{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manishm/miniconda3/envs/mvdmlab_preproc_nwbconverter/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "import pynwb\n",
    "from pynwb import NWBHDF5IO, NWBFile\n",
    "from pynwb.file import Subject\n",
    "\n",
    "from neuroconv.datainterfaces.ecephys.spikeglx.spikeglxdatainterface import SpikeGLXRecordingInterface\n",
    "from neuroconv.tools.spikeinterface.spikeinterface import (\n",
    "    add_electrodes_info_to_nwbfile, \n",
    "    add_devices_to_nwbfile, \n",
    "    add_electrode_groups_to_nwbfile,\n",
    "    add_electrodes_to_nwbfile, \n",
    "    _get_electrode_table_indices_for_recording,\n",
    "    _get_electrodes_table_global_ids\n",
    ")\n",
    "import manimoh_utils as mu\n",
    "import manimoh_nwb_converters as mnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your custom extension\n",
    "from ndx_mvdmlab_metadata import (\n",
    "    LabMetaDataExtension, \n",
    "    ProbeExtension, \n",
    "    OdorantInfoExtension, \n",
    "    ExperimentalBlockExtension, \n",
    "    PreprocessedAnnotationExtension\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lab_metadata_to_nwb(nwbfile, session_metadata):\n",
    "    '''\n",
    "    Function to add lab-specific metadata to the NWB file.\n",
    "    '''\n",
    "    # Create probe extension for probe 1\n",
    "    probe1_extension = None\n",
    "    if 'probe1_ID' in session_metadata:\n",
    "        probe1_metadata = {}\n",
    "        for key in session_metadata:\n",
    "            if 'probe1_' in key and 'ID' not in key and 'location' not in key:\n",
    "                if 'Depth' not in key:\n",
    "                    probe1_metadata[key.split('_')[-1]] = session_metadata[key]\n",
    "                else:\n",
    "                    probe1_metadata['depth'] = session_metadata[key]\n",
    "\n",
    "        probe1_extension = ProbeExtension(\n",
    "            name='probe1',\n",
    "            ID=session_metadata.get('probe1_ID'),\n",
    "            **probe1_metadata\n",
    "        )\n",
    "\n",
    "    # Create probe extension for probe 2 (if exists)\n",
    "    probe2_extension = None\n",
    "    if 'probe2_ID' in session_metadata:\n",
    "        probe2_metadata = {}\n",
    "        for key in session_metadata:\n",
    "            if 'probe2_' in key and 'ID' not in key and 'location' not in key:\n",
    "                if 'Depth' not in key:\n",
    "                    probe2_metadata[key.split('_')[-1]] = session_metadata[key]\n",
    "                else:\n",
    "                    probe2_metadata['depth'] = session_metadata[key]\n",
    "        \n",
    "        probe2_extension = ProbeExtension(\n",
    "            name='probe2',\n",
    "            ID=session_metadata.get('probe2_ID'),\n",
    "            **probe2_metadata\n",
    "        )\n",
    "\n",
    "    # Create odorant info extension\n",
    "    odorant_info = {}\n",
    "    for odor in ['A', 'B', 'C', 'D', 'E', 'F', 'G']:\n",
    "        odor_field = f'odor{odor}'\n",
    "        if odor_field in session_metadata:\n",
    "            key = f'Odor {odor}'\n",
    "            odorant_info[key] = session_metadata[odor_field]\n",
    "    \n",
    "    odorant_info_extension = None\n",
    "    if odorant_info:\n",
    "        odorant_info_extension = OdorantInfoExtension(\n",
    "            name='odorant_info',\n",
    "            **odorant_info\n",
    "        )\n",
    "\n",
    "    # Create experimental block extension\n",
    "    block_info = {}\n",
    "    for block in [1, 2, 3]:\n",
    "        block_type_field = f'block{block}_type'\n",
    "        if block_type_field in session_metadata:\n",
    "            block_info[block_type_field] = ','.join(session_metadata[block_type_field])\n",
    "    \n",
    "    block_info_extension = None\n",
    "    if block_info:\n",
    "        block_info_extension = ExperimentalBlockExtension(\n",
    "            name='block_info',\n",
    "            **block_info\n",
    "        )\n",
    "\n",
    "    # Create preprocessed annotation extension\n",
    "    preprocessed_annotations = {}\n",
    "    \n",
    "    # Pattern for matching SWR and control channel metadata\n",
    "    annotation_patterns = [\n",
    "        r'imec(\\d+)_shank(\\d+)_SWR_channel',\n",
    "        r'imec(\\d+)_best_SWR_channel',\n",
    "        r'imec(\\d+)_best_control_channel'\n",
    "    ]\n",
    "    \n",
    "    # Find all keys in session_metadata that match our patterns\n",
    "    for key in session_metadata:\n",
    "        for pattern in annotation_patterns:\n",
    "            if re.match(pattern, key):\n",
    "                preprocessed_annotations[key] = session_metadata[key]\n",
    "                break\n",
    "    \n",
    "    annotation_extension = None\n",
    "    if preprocessed_annotations:\n",
    "        annotation_extension = PreprocessedAnnotationExtension(\n",
    "            name='preprocessed_annotations',\n",
    "            **preprocessed_annotations\n",
    "        )\n",
    "\n",
    "    # Prepare the metadata dictionary for LabMetaDataExtension\n",
    "    lab_metadata_dict = {\n",
    "        'name': 'LabMetaData',\n",
    "    }\n",
    "    \n",
    "    # Add probes if they exist\n",
    "    if probe1_extension:\n",
    "        lab_metadata_dict['probe1'] = probe1_extension\n",
    "    \n",
    "    if probe2_extension:\n",
    "        lab_metadata_dict['probe2'] = probe2_extension\n",
    "    \n",
    "    # Add other extensions if they exist\n",
    "    if odorant_info_extension:\n",
    "        lab_metadata_dict['odorant_info'] = odorant_info_extension\n",
    "    \n",
    "    if block_info_extension:\n",
    "        lab_metadata_dict['block_info'] = block_info_extension\n",
    "    \n",
    "    if annotation_extension:\n",
    "        lab_metadata_dict['preprocessed_annotations'] = annotation_extension\n",
    "\n",
    "    # Populate metadata extension \n",
    "    lab_metadata = LabMetaDataExtension(**lab_metadata_dict)\n",
    "\n",
    "    # Add to file\n",
    "    nwbfile.add_lab_meta_data(lab_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dirpath = '/mnt/datasets/incoming/mvdm/OdorSequence/sourcedata/raw/M541/M541-2024-08-31_g0'\n",
    "preprocessed_dirpath = '/mnt/datasets/incoming/mvdm/OdorSequence/sourcedata/preprocessed/M541/M541-2024-08-31'\n",
    "output_nwb_filepath = '/home/manishm/test_2024-08-31.nwb'\n",
    "overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = Path(raw_dirpath)\n",
    "preprocessed_dir = Path(preprocessed_dirpath)\n",
    "output_nwb_file = Path(output_nwb_filepath)\n",
    "\n",
    "if output_nwb_file.exists() and not overwrite:\n",
    "    raise FileExistsError(f\"File {output_nwb_file} already exists. Set overwrite=True to overwrite.\")\n",
    "\n",
    "# Get preprocessed_metadata present in ExpKeys file to determine which interfaces to create\n",
    "preprocessed_metadata = mu.parse_expkeys(preprocessed_dir)\n",
    "\n",
    "raw_interface = SpikeGLXRecordingInterface(folder_path=raw_dir, stream_id=f\"{preprocessed_metadata['probe1_ID']}.ap\")\n",
    "raw_metadata = raw_interface.get_metadata()\n",
    "\n",
    "out_nwb = NWBFile(\n",
    "session_description=preprocessed_metadata['notes'], \n",
    "identifier='-'.join([preprocessed_metadata['subject'], preprocessed_metadata['date']]),\n",
    "session_start_time=raw_metadata['NWBFile']['session_start_time'].astimezone(), \n",
    "experimenter=[\n",
    "    preprocessed_metadata['experimenter']\n",
    "],\n",
    "lab=\"vandermeerlab\",\n",
    "institution=\"Dartmouth College\",\n",
    "experiment_description=\"Head-fixed mouse presented with odor sequences\",\n",
    "keywords=[\"ecephys\", \"neuropixels\", \"odor-sequences\", \"hippocampus\"], # needs to be edited\n",
    ")\n",
    "\n",
    "sub_age = (datetime.strptime(preprocessed_metadata['date'], '%Y-%m-%d') - \\\n",
    "    datetime.strptime(preprocessed_metadata['DOB'], '%Y-%m-%d')).days//7\n",
    "# Create subject\n",
    "subject = Subject(subject_id=preprocessed_metadata['subject'], age=f\"P{sub_age}W\", \n",
    "    species = \"Mus musculus\", description = \"Headbar-ed mouse with craniotomies over dCA1\", \n",
    "    sex = preprocessed_metadata['sex'],\n",
    "    )\n",
    "out_nwb.subject = subject\n",
    "\n",
    "# Add all electrodes from the first probe\n",
    "# Adding depth as a property\n",
    "distance_from_tip = raw_interface.recording_extractor.get_channel_locations()[:,1]\n",
    "this_depth = (preprocessed_metadata[\"probe1_Depth\"]*1000 - distance_from_tip) * \\\n",
    "    np.cos(math.radians(preprocessed_metadata[\"probe1_insertion_roll\"]))\n",
    "raw_interface.recording_extractor.set_property('recording_depth', values=this_depth)\n",
    "# Adding label and hemisphere as additional properties\n",
    "imec_id = [(x.split('.')[0]).replace('imec','') for x in raw_interface.recording_extractor.get_channel_ids()]\n",
    "channel_id = [(x.split('#')[-1]) for x in raw_interface.recording_extractor.get_channel_ids()]\n",
    "shank_id =  raw_interface.recording_extractor.get_channel_groups().tolist()\n",
    "this_label = [f\"imec{imec_id[x]}_shank{shank_id[x]}_{channel_id[x]}\" for x in range(len(imec_id))]\n",
    "raw_interface.recording_extractor.set_property('label', values=this_label)\n",
    "this_hemi = np.repeat(preprocessed_metadata['probe1_hemisphere'], len(this_label))\n",
    "raw_interface.recording_extractor.set_property('hemisphere', values=this_hemi)\n",
    "# Adding description of the new column to the metadata (Otherwise nwbinspector will cry that there is no description)\n",
    "raw_metadata['Ecephys']['Electrodes'].append({\n",
    "    'name': 'recording_depth',\n",
    "    'description': 'Depth of electrode from brain surface in micrometers, based on experimental annotation'\n",
    "})\n",
    "raw_metadata['Ecephys']['Electrodes'].append({\n",
    "    'name': 'label',\n",
    "    'description': 'Unique human-readable label for each recording channel'\n",
    "})\n",
    "raw_metadata['Ecephys']['Electrodes'].append({\n",
    "    'name': 'hemisphere',\n",
    "    'description': 'Brain hemisphere where this recording electrode was present'\n",
    "})\n",
    "add_electrodes_info_to_nwbfile(recording=raw_interface.recording_extractor, \n",
    "    nwbfile=out_nwb, metadata=raw_metadata)\n",
    "# if 2nd probe exists, then add electrodes from that too\n",
    "if 'probe2_ID' in preprocessed_metadata.keys():\n",
    "    raw_interface2 = SpikeGLXRecordingInterface(folder_path=raw_dir, stream_id=f\"{preprocessed_metadata['probe2_ID']}.ap\")\n",
    "    raw_metadata2 = raw_interface2.get_metadata()\n",
    "    distance_from_tip = raw_interface2.recording_extractor.get_channel_locations()[:,1]\n",
    "    this_depth = (preprocessed_metadata[\"probe2_Depth\"]*1000 - distance_from_tip) * \\\n",
    "        np.cos(math.radians(preprocessed_metadata[\"probe2_insertion_roll\"]))\n",
    "    raw_interface2.recording_extractor.set_property('recording_depth', values=this_depth)\n",
    "    # Adding label and hemisphere as additional properties\n",
    "    imec_id2 = [(x.split('.')[0]).replace('imec','') for x in raw_interface2.recording_extractor.get_channel_ids()]\n",
    "    channel_id2 = [(x.split('#')[-1]) for x in raw_interface2.recording_extractor.get_channel_ids()]\n",
    "    shank_id2 =  raw_interface2.recording_extractor.get_channel_groups().tolist()\n",
    "    this_label2 = [f\"imec{imec_id2[x]}_shank{shank_id2[x]}_{channel_id2[x]}\" for x in range(len(imec_id2))]\n",
    "    raw_interface2.recording_extractor.set_property('label', values=this_label2)\n",
    "    this_hemi2 = np.repeat(preprocessed_metadata['probe1_hemisphere'], len(this_label2))\n",
    "    raw_interface2.recording_extractor.set_property('hemisphere', values=this_hemi2)\n",
    "    # Adding description of the new column to the metadata (Otherwise nwbinspector will cry that there is no description)\n",
    "    raw_metadata2['Ecephys']['Electrodes'].append({\n",
    "        'name': 'recording_depth',\n",
    "        'description': 'Depth of electrode from brain surface in micrometers, based on experimental annotation'\n",
    "    })\n",
    "    raw_metadata2['Ecephys']['Electrodes'].append({\n",
    "        'name': 'label',\n",
    "        'description': 'Unique human-readable label for each recording channel'\n",
    "    })\n",
    "    raw_metadata2['Ecephys']['Electrodes'].append({\n",
    "        'name': 'hemisphere',\n",
    "        'description': 'Brain hemisphere where this recording electrode was present'\n",
    "    })\n",
    "    add_electrodes_info_to_nwbfile(recording=raw_interface2.recording_extractor,\n",
    "        nwbfile=out_nwb, metadata=raw_metadata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add LFP data\n",
    "device_labels = []\n",
    "if os.path.exists(os.path.join(preprocessed_dir,\"imec0_clean_lfp.mat\")):\n",
    "    device_labels.append(\"imec0\")\n",
    "if os.path.exists(os.path.join(preprocessed_dir,\"imec1_clean_lfp.mat\")):\n",
    "    device_labels.append(\"imec1\")\n",
    "# # add LFP electrodes table to nwb file\n",
    "# mnc.add_lfp_electrodes_to_nwb(preprocessed_dir, out_nwb, preprocessed_metadata, device_labels)\n",
    "# add LFP traces to nwb file\n",
    "mnc.add_lfp_data_to_nwb(preprocessed_dir, out_nwb, preprocessed_metadata, device_labels)\n",
    "    \n",
    "# Add spiking data\n",
    "device_labels = []\n",
    "if os.path.exists(os.path.join(preprocessed_dir,\"clean_units_imec0.mat\")):\n",
    "    device_labels.append(\"imec0\")\n",
    "if os.path.exists(os.path.join(preprocessed_dir,\"clean_units_imec1.mat\")):\n",
    "    device_labels.append(\"imec1\")\n",
    "# add spike times, waveforms, and other information to nwb file\n",
    "mnc.add_sorting_data_to_nwb(preprocessed_dir, out_nwb, preprocessed_metadata, device_labels)\n",
    "\n",
    "# # Add behavioral epochs\n",
    "# mnc.add_intervals_to_nwb(preprocessed_dir, out_nwb, preprocessed_metadata)\n",
    "\n",
    "# # Add lab metadata using the custom extension\n",
    "# mnc.add_lab_metadata_to_nwb(out_nwb, preprocessed_metadata)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the actual NWB File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "io = NWBHDF5IO(output_nwb_filepath, mode='w')\n",
    "io.write(out_nwb)\n",
    "io.close() # This is crtitcal and nwbinspector won't work without it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_nwb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvdmlab_preproc_nwbconverter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
