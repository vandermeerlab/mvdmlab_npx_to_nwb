{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import shutil\n",
    "from neuroconv.utils import load_dict_from_file, dict_deep_update\n",
    "import h5py\n",
    "import numpy as np\n",
    "from pynwb import NWBHDF5IO, NWBFile\n",
    "import os\n",
    "import pynwb\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('E:\\\\odor-pixels\\\\M541-2024-08-31\\\\imec0_clean_lfp.mat', 'r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file['imec0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get channel ids in array\n",
    "q = np.asarray(file['imec0']['channel_ids'][:], dtype='uint32')\n",
    "q = q.T.view('U1')\n",
    "channel_ids = np.asarray([''.join(x).strip() for x in q])\n",
    "channel_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get shank_ids in array\n",
    "shank_id = file['imec0']['shank_ids'][:].flatten()\n",
    "shank_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get depths ids in array TODO: Needs subtraction from ExpKeys.recordingDepth\n",
    "depths = file['imec0']['depths'][:].flatten()\n",
    "depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get lfp_fs\n",
    "lfp_fs = file['imec0']['lfp_fs'][:].flatten()\n",
    "lfp_fs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get lfp_tvec in array\n",
    "lfp_tvec = file['imec0']['lfp_tvec'][:].flatten()\n",
    "lfp_tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get lfp_traces in array\n",
    "lfp_data= file['imec0']['lfp_traces'][:]\n",
    "lfp_data = np.transpose(lfp_data)\n",
    "lfp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile = NWBFile(\n",
    "    session_description=\"my first synthetic recording\",\n",
    "    identifier='-'.join([expkeys['subject'], expkeys['date']]),\n",
    "    session_start_time=datetime.now(tzlocal()), # Get from .meta file\n",
    "    experimenter=[\n",
    "        \"\"Mohapatra, Manish\",\"\n",
    "    ],\n",
    "    lab=\"vandermeerlab\",\n",
    "    institution=\"Dartmouth College\",\n",
    "    experiment_description=\"Head-fixed mouse presented with odor sequences\",\n",
    "    keywords=[\"ecephys\", \"exploration\", \"wanderlust\"],\n",
    ")\n",
    "device = nwbfile.create_device(\n",
    "    name=\"imec0\", description=\"NPX2.0\", manufacturer=\"IMEC\"\n",
    ")\n",
    "nwbfile.add_electrode_column(name=\"channel_id\", description=\"Identifier for the channel on the probe\")\n",
    "\n",
    "unique_shanks = np.unique(shank_id).tolist()\n",
    "electrode_counter = 0\n",
    "for iShank in unique_shanks:\n",
    "    electrode_group = nwbfile.create_electrode_group(\n",
    "        name=\"shank{}\".format(iShank),\n",
    "        description=\"electrode group for shank {}\".format(iShank),\n",
    "        device=device,\n",
    "        location=\"brain area\", # Need to figure this out, should this be the same as depth\n",
    "    )\n",
    "    # add electrodes to the electrode table\n",
    "    for ielec,elec in enumerate(np.where(shank_id == iShank)[0]):\n",
    "        # print\n",
    "        nwbfile.add_electrode(\n",
    "            group=electrode_group,\n",
    "            channel_id = channel_ids[elec],\n",
    "            location=\"brain area\",  # Need to figure this out, should this be the same as depth\n",
    "        )\n",
    "        electrode_counter += 1\n",
    "\n",
    "# nwbfile.electrodes.to_dataframe() # Distplay the electrode table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_table = nwbfile.create_electrode_table_region(\n",
    "    region=list(range(electrode_counter)),  # reference row indices 0 to N-1\n",
    "    description=\"LFP electrodes\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb.ecephys import ElectricalSeries, LFP\n",
    "lfp_es = ElectricalSeries(name='LFP', data=lfp_data, electrodes=lfp_table, rate=lfp_fs[0], starting_time=lfp_tvec[0])\n",
    "ecephys_module = nwbfile.create_processing_module(\n",
    "    name=\"ecephys\", description=\"processed extracellular electrophysiology data\"\n",
    ")\n",
    "ecephys_module.add(lfp_es)\n",
    "# TODO: Add conversion factor from .meta file , but we already get 'scaled data' from spikeinterface'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with NWBHDF5IO(\"E:\\\\odor-pixels\\\\M541-2024-08-31\\\\test.nwb\", \"w\") as io:\n",
    "    io.write(nwbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with NWBHDF5IO(\"E:\\\\odor-pixels\\\\M541-2024-08-31\\\\test.nwb\", \"r\") as io:\n",
    "    nwbfile = io.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io = NWBHDF5IO(\"E:\\\\odor-pixels\\\\M541-2024-08-31\\\\test.nwb\", \"r\")\n",
    "nwb_file = io.read()\n",
    "nwb_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pynwb.validate(nwb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('E:\\\\odor-pixels\\\\M541-2024-08-31\\\\clean_units_imec0.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'depths', 'unit_ids', 'channel_ids', 'spike_train', 'shank_ids', 'mean_waveforms'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spiking data is in older_matlab style\n",
    "spike_data = sio.loadmat('E:\\\\odor-pixels\\\\M541-2024-08-31\\\\clean_units_imec0.mat')\n",
    "spike_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 90)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to extract average waveform\n",
    "all_wv = spike_data['mean_waveforms'].squeeze()\n",
    "big_idx = [np.argmax(abs(np.max(all_wv[x], axis=1) - np.min(all_wv[x], axis=1))) for x in range(all_wv.shape[0])]\n",
    "big_wv = np.asarray([all_wv[x][y][:] for x,y in enumerate(big_idx)])\n",
    "big_wv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4742,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_trains[0][0].squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get spike_trains\n",
    "spike_trains = spike_data['spike_train'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get depths #TODO: Needs subtraction from ExpKeys.recordingDepth \n",
    "spike_data['depths'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3,\n",
       "       3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2,\n",
       "       3, 3, 3, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 1, 1, 3, 0,\n",
       "       0, 0, 0, 0, 3, 0, 3, 1, 0, 0, 0, 0, 1, 1, 1, 3, 0, 1, 0, 0, 0, 2,\n",
       "       1, 0, 0, 0, 3, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to get shank_ids #TODO: Need to add device + shank\n",
    "spike_data['shank_ids'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to get channel_ids\n",
    "spike_data['channel_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['imec0_0  ', 'imec0_3  ', 'imec0_4  ', 'imec0_5  ', 'imec0_6  ',\n",
       "       'imec0_8  ', 'imec0_23 ', 'imec0_40 ', 'imec0_53 ', 'imec0_54 ',\n",
       "       'imec0_62 ', 'imec0_63 ', 'imec0_64 ', 'imec0_69 ', 'imec0_72 ',\n",
       "       'imec0_73 ', 'imec0_74 ', 'imec0_76 ', 'imec0_77 ', 'imec0_79 ',\n",
       "       'imec0_94 ', 'imec0_97 ', 'imec0_99 ', 'imec0_109', 'imec0_110',\n",
       "       'imec0_114', 'imec0_115', 'imec0_116', 'imec0_117', 'imec0_118',\n",
       "       'imec0_122', 'imec0_139', 'imec0_140', 'imec0_142', 'imec0_146',\n",
       "       'imec0_149', 'imec0_153', 'imec0_155', 'imec0_160', 'imec0_161',\n",
       "       'imec0_165', 'imec0_170', 'imec0_175', 'imec0_176', 'imec0_177',\n",
       "       'imec0_184', 'imec0_188', 'imec0_189', 'imec0_192', 'imec0_197',\n",
       "       'imec0_200', 'imec0_201', 'imec0_210', 'imec0_211', 'imec0_212',\n",
       "       'imec0_213', 'imec0_214', 'imec0_216', 'imec0_220', 'imec0_231',\n",
       "       'imec0_234', 'imec0_237', 'imec0_243', 'imec0_246', 'imec0_248',\n",
       "       'imec0_257', 'imec0_261', 'imec0_263', 'imec0_264', 'imec0_266',\n",
       "       'imec0_276', 'imec0_277', 'imec0_278', 'imec0_279', 'imec0_284',\n",
       "       'imec0_285', 'imec0_289', 'imec0_290', 'imec0_295', 'imec0_297',\n",
       "       'imec0_300', 'imec0_302', 'imec0_304', 'imec0_306', 'imec0_354',\n",
       "       'imec0_355', 'imec0_356', 'imec0_357', 'imec0_358', 'imec0_359',\n",
       "       'imec0_360', 'imec0_361', 'imec0_362', 'imec0_364', 'imec0_366',\n",
       "       'imec0_367', 'imec0_369', 'imec0_370', 'imec0_371', 'imec0_373',\n",
       "       'imec0_374', 'imec0_376', 'imec0_377', 'imec0_378', 'imec0_379',\n",
       "       'imec0_380', 'imec0_385', 'imec0_386', 'imec0_387', 'imec0_388',\n",
       "       'imec0_391', 'imec0_393', 'imec0_394', 'imec0_395', 'imec0_396',\n",
       "       'imec0_397'], dtype='<U9')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_data['unit_ids']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocessed_nwb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
