{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import shutil\n",
    "from neuroconv.utils import load_dict_from_file, dict_deep_update\n",
    "import h5py\n",
    "import numpy as np\n",
    "from pynwb import NWBFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manimoh_nwb_converters import OdorSeqNWBConverter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_to_nwb(data_dir_path: str | Path, output_dir_path: str | Path, stub_test: bool = False):\n",
    "\n",
    "    data_dir_path = Path(data_dir_path)\n",
    "    output_dir_path = Path(output_dir_path)\n",
    "    if stub_test:\n",
    "        output_dir_path = output_dir_path / \"nwb_stub\"\n",
    "    output_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    session_id = \"sample_session\"\n",
    "    subject_id = \"SL18\"\n",
    "    nwbfile_path = output_dir_path / f\"{session_id}.nwb\"\n",
    "\n",
    "    source_data = dict()\n",
    "    conversion_options = dict()\n",
    "\n",
    "    # Add Ephys (can we do without this?)\n",
    "    # file_path = (\n",
    "    #     data_dir_path\n",
    "    #     / \"SL18_D19\"\n",
    "    #     / \"SL18_D19_S01_F01_BOX_SLP_20230503_112642\"\n",
    "    #     / \"SL18_D19_S01_F01_BOX_SLP_20230503_112642.rec\"\n",
    "    # )\n",
    "    # source_data.update(dict(Recording=dict(file_path=file_path)))\n",
    "    # conversion_options.update(dict(Recording=dict(stub_test=stub_test)))\n",
    "\n",
    "    # # Add Sorting\n",
    "    # spike_times_folder_path = data_dir_path / \"SL18_D19\" / \"SL18_D19.SpikesFinal\"\n",
    "    # unit_stats_folder_path = data_dir_path / \"SL18_D19\" / \"SL18_D19.ExportedUnitStats\"\n",
    "    # source_data.update(\n",
    "    #     dict(\n",
    "    #         Sorting=dict(spike_times_folder_path=spike_times_folder_path, unit_stats_folder_path=unit_stats_folder_path)\n",
    "    #     )\n",
    "    # )\n",
    "    # conversion_options.update(dict(Sorting=dict()))\n",
    "\n",
    "    # Add LFP\n",
    "    folder_path = data_dir_path / \"SL18_D19\" / \"SL18_D19.LFP\"\n",
    "    source_data.update(dict(LFP=dict(folder_path=folder_path)))\n",
    "    conversion_options.update(dict(LFP=dict(stub_test=stub_test)))\n",
    "\n",
    "\n",
    "    # # Add Behavior\n",
    "    # folder_path = \"/Volumes/T7/CatalystNeuro/Jadhav/SubLearnProject/SL18_D19/SL18_D19.DIO\"\n",
    "    # source_data.update(dict(Behavior=dict(folder_path=folder_path)))\n",
    "    # conversion_options.update(dict(Behavior=dict()))\n",
    "\n",
    "    converter = OdorSeqNWBConverter(source_data=source_data)\n",
    "\n",
    "    # Add datetime to conversion\n",
    "    metadata = converter.get_metadata()\n",
    "    metadata[\"NWBFile\"][\"session_start_time\"] = datetime.datetime(2023, 5, 3, 11, 26, 42, tzinfo=ZoneInfo(\"US/Eastern\"))\n",
    "\n",
    "    # Update default metadata with the editable in the corresponding yaml file\n",
    "    editable_metadata_path = Path(__file__).parent / \"olson_2024_metadata.yaml\"\n",
    "    editable_metadata = load_dict_from_file(editable_metadata_path)\n",
    "    metadata = dict_deep_update(metadata, editable_metadata)\n",
    "\n",
    "    # Run conversion\n",
    "    converter.run_conversion(metadata=metadata, nwbfile_path=nwbfile_path, conversion_options=conversion_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('E:\\\\odor-pixels\\\\M541-2024-08-31\\\\imec0_clean_lfp.mat', 'r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['channel_ids', 'depths', 'lfp_fs', 'lfp_traces', 'lfp_tvec', 'shank_ids']>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['imec0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['imec0.ap#AP112', 'imec0.ap#AP126', 'imec0.ap#AP138',\n",
       "       'imec0.ap#AP200', 'imec0.ap#AP214', 'imec0.ap#AP226',\n",
       "       'imec0.ap#AP288', 'imec0.ap#AP302', 'imec0.ap#AP162',\n",
       "       'imec0.ap#AP176', 'imec0.ap#AP188', 'imec0.ap#AP250',\n",
       "       'imec0.ap#AP264', 'imec0.ap#AP276', 'imec0.ap#AP338',\n",
       "       'imec0.ap#AP352', 'imec0.ap#AP304', 'imec0.ap#AP318',\n",
       "       'imec0.ap#AP330', 'imec0.ap#AP8', 'imec0.ap#AP22', 'imec0.ap#AP34',\n",
       "       'imec0.ap#AP96', 'imec0.ap#AP110', 'imec0.ap#AP354',\n",
       "       'imec0.ap#AP368', 'imec0.ap#AP380', 'imec0.ap#AP58',\n",
       "       'imec0.ap#AP72', 'imec0.ap#AP84', 'imec0.ap#AP146',\n",
       "       'imec0.ap#AP160'], dtype='<U14')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to get channel ids in array\n",
    "q = np.asarray(file['imec0']['channel_ids'][:], dtype='uint32')\n",
    "q = q.T.view('U1')\n",
    "channel_ids = np.asarray([''.join(x).strip() for x in q])\n",
    "channel_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to get shank_ids in array\n",
    "shank_id = file['imec0']['shank_ids'][:].flatten()\n",
    "shank_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 480.,  585.,  675.,  780.,  885.,  975., 1080., 1185.,  495.,\n",
       "        600.,  690.,  795.,  900.,  990., 1095., 1200.,  480.,  585.,\n",
       "        675.,  780.,  885.,  975., 1080., 1185.,  495.,  600.,  690.,\n",
       "        795.,  900.,  990., 1095., 1200.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to get depths ids in array TODO: Needs subtraction from ExpKeys.recordingDepth\n",
    "depths = file['imec0']['depths'][:].flatten()\n",
    "depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to get lfp_fs\n",
    "lfp_fs = file['imec0']['lfp_fs'][:].flatten()\n",
    "lfp_fs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000000e+00, 4.0000000e-04, 8.0000000e-04, ..., 6.1901092e+03,\n",
       "       6.1901096e+03, 6.1901100e+03])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to get lfp_tvec in array\n",
    "lfp_tvec = file['imec0']['lfp_tvec'][:].flatten()\n",
    "lfp_tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -30.273438 ,   48.4375   ,  102.92969  , ..., -118.06641  ,\n",
       "        -105.95703  ,  -93.84766  ],\n",
       "       [ -48.4375   ,  169.53125  ,  320.89844  , ..., -136.23047  ,\n",
       "        -112.01172  ,  -81.73828  ],\n",
       "       [ -33.30078  ,    6.0546875,   30.273438 , ...,  -18.164062 ,\n",
       "           9.082031 ,   36.328125 ],\n",
       "       ...,\n",
       "       [ -18.164062 ,   93.84766  ,  169.53125  , ..., -163.47656  ,\n",
       "        -148.33984  , -127.14844  ],\n",
       "       [  -6.0546875,   84.765625 ,  151.36719  , ..., -193.75     ,\n",
       "        -190.72266  , -181.64062  ],\n",
       "       [ -27.246094 ,  -27.246094 ,  -27.246094 , ..., -133.20312  ,\n",
       "        -124.12109  , -112.01172  ]], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to get lfp_traces in array\n",
    "lfp_data= file['imec0']['lfp_traces'][:]\n",
    "lfp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile = NWBFile(\n",
    "    session_description=\"my first synthetic recording\",\n",
    "    identifier=str(uuid4()),\n",
    "    session_start_time=datetime.now(tzlocal()),\n",
    "    experimenter=[\n",
    "        \"Baggins, Bilbo\",\n",
    "    ],\n",
    "    lab=\"Bag End Laboratory\",\n",
    "    institution=\"University of Middle Earth at the Shire\",\n",
    "    experiment_description=\"I went on an adventure to reclaim vast treasures.\",\n",
    "    keywords=[\"ecephys\", \"exploration\", \"wanderlust\"],\n",
    "    related_publications=\"doi:10.1016/j.neuron.2016.12.011\",\n",
    ")\n",
    "device = nwbfile.create_device(\n",
    "    name=\"imec0\", description=\"NPX2.0\", manufacturer=\"IMEC\"\n",
    ")\n",
    "nwbfile.add_electrode_column(name=\"channel_id\", description=\"Identifier for the channel on the probe\")\n",
    "\n",
    "unique_shanks = np.unique(shank_id).tolist()\n",
    "electrode_counter = 0\n",
    "for iShank in unique_shanks:\n",
    "    electrode_group = nwbfile.create_electrode_group(\n",
    "        name=\"shank{}\".format(iShank),\n",
    "        description=\"electrode group for shank {}\".format(iShank),\n",
    "        device=device,\n",
    "        location=\"brain area\", # Need to figure this out \n",
    "    )\n",
    "    # add electrodes to the electrode table\n",
    "    for ielec,elec in enumerate(np.where(shank_id == iShank)[0]):\n",
    "        # print\n",
    "        nwbfile.add_electrode(\n",
    "            group=electrode_group,\n",
    "            channel_id = channel_ids[elec],\n",
    "            location=\"brain area\",  # Need to figure this out \n",
    "        )\n",
    "        electrode_counter += 1\n",
    "# The line below will display the electrode table\n",
    "# nwbfile.electrodes.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ElectricalSeries.__init__: incorrect type for 'electrodes' (got 'ndarray', expected 'DynamicTableRegion')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lfp_es \u001b[38;5;241m=\u001b[39m \u001b[43mElectricalSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLFP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlfp_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melectrodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlfp_fs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarting_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlfp_tvec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mvdmlab\\miniconda3\\envs\\preprocessed_nwb\\lib\\site-packages\\hdmf\\utils.py:667\u001b[0m, in \u001b[0;36mdocval.<locals>.dec.<locals>.func_call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 667\u001b[0m     pargs \u001b[38;5;241m=\u001b[39m \u001b[43m_check_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpargs)\n",
      "File \u001b[1;32mc:\\Users\\mvdmlab\\miniconda3\\envs\\preprocessed_nwb\\lib\\site-packages\\hdmf\\utils.py:660\u001b[0m, in \u001b[0;36mdocval.<locals>.dec.<locals>._check_args\u001b[1;34m(args, kwargs)\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse_err:\n\u001b[0;32m    659\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(parse_err))\n\u001b[1;32m--> 660\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExceptionType(msg)\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parsed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: ElectricalSeries.__init__: incorrect type for 'electrodes' (got 'ndarray', expected 'DynamicTableRegion')"
     ]
    }
   ],
   "source": [
    "from pynwb.ecephys import ElectricalSeries, LFP\n",
    "lfp_es = ElectricalSeries(name='LFP', data=lfp_data, electrodes=channel_ids, rate=lfp_fs[0], starting_time=lfp_tvec[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocessed_nwb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
